{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc33e3ee",
   "metadata": {},
   "source": [
    "🔍 What is SVM?\n",
    "Imagine you have two kinds of fruits: 🍎 Apples and 🍊 Oranges, and you want to build a machine that can look at a fruit and decide whether it’s an apple or an orange.\n",
    "\n",
    "You collect data like:\n",
    "\n",
    "Weight\n",
    "\n",
    "Color\n",
    "\n",
    "Size\n",
    "\n",
    "You can plot these features on a graph. Now you want to draw a line (or curve) that separates all apples from oranges.\n",
    "\n",
    "SVM helps you do exactly that.\n",
    "\n",
    "✅ SVM – In Simple Words\n",
    "SVM is like a very smart border drawer:\n",
    "\n",
    "It draws a line (or a boundary) that separates your classes (apple/orange) with the biggest possible gap (called margin).\n",
    "\n",
    "It focuses only on the most important data points — the ones that are closest to the border. These are called Support Vectors.\n",
    "\n",
    "🧠 Real Intuition\n",
    "Let’s say:\n",
    "\n",
    "You want to split your room into two parts using a rope so that toys are on one side and books on the other.\n",
    "\n",
    "SVM will pull the rope in such a way that it's not too close to any toy or book — it wants maximum space on both sides.\n",
    "\n",
    "That rope = decision boundary,\n",
    "Closest toy/book = support vectors,\n",
    "The space in between = margin.\n",
    "\n",
    "🔄 What if toys and books are mixed and not separable by a straight rope?\n",
    "SVM then uses a \"magic trick\" called a kernel.\n",
    "\n",
    "Imagine lifting toys and books into the air and then slicing them with a flat sheet. Suddenly, they can be separated! ✨\n",
    "This trick is done using something called a Kernel Function, like:\n",
    "\n",
    "Linear Kernel (straight line)\n",
    "\n",
    "RBF Kernel (curved boundary — more flexible)\n",
    "\n",
    "🔧 SVM Important Settings (Hyperparameters)\n",
    "🔸 C – Regularization\n",
    "Controls how much SVM cares about correctly classifying each training example vs having a wider margin.\n",
    "\n",
    "Low C → allow some mistakes but wider margin.\n",
    "\n",
    "High C → tries to classify everything right, even if the margin is smaller.\n",
    "\n",
    "🔸 gamma – Only for RBF kernel\n",
    "Controls how far a single training example affects the boundary.\n",
    "\n",
    "Low gamma → smoother boundary.\n",
    "\n",
    "High gamma → more complex, wiggly boundary (can overfit).\n",
    "\n",
    "🛠 What will we do in this task?\n",
    "Load Breast Cancer Dataset 🧬 (with sklearn.datasets)\n",
    "\n",
    "Preprocess the data (scale features using StandardScaler)\n",
    "\n",
    "Train two SVM models:\n",
    "\n",
    "Linear SVM\n",
    "\n",
    "Non-linear SVM (with RBF kernel)\n",
    "\n",
    "Visualize the decision boundary (for simple 2D data)\n",
    "\n",
    "Tune C and gamma to improve results\n",
    "\n",
    "Use cross-validation to test performance\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
