{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc33e3ee",
   "metadata": {},
   "source": [
    "ğŸ” What is SVM?\n",
    "Imagine you have two kinds of fruits: ğŸ Apples and ğŸŠ Oranges, and you want to build a machine that can look at a fruit and decide whether itâ€™s an apple or an orange.\n",
    "\n",
    "You collect data like:\n",
    "\n",
    "Weight\n",
    "\n",
    "Color\n",
    "\n",
    "Size\n",
    "\n",
    "You can plot these features on a graph. Now you want to draw a line (or curve) that separates all apples from oranges.\n",
    "\n",
    "SVM helps you do exactly that.\n",
    "\n",
    "âœ… SVM â€“ In Simple Words\n",
    "SVM is like a very smart border drawer:\n",
    "\n",
    "It draws a line (or a boundary) that separates your classes (apple/orange) with the biggest possible gap (called margin).\n",
    "\n",
    "It focuses only on the most important data points â€” the ones that are closest to the border. These are called Support Vectors.\n",
    "\n",
    "ğŸ§  Real Intuition\n",
    "Letâ€™s say:\n",
    "\n",
    "You want to split your room into two parts using a rope so that toys are on one side and books on the other.\n",
    "\n",
    "SVM will pull the rope in such a way that it's not too close to any toy or book â€” it wants maximum space on both sides.\n",
    "\n",
    "That rope = decision boundary,\n",
    "Closest toy/book = support vectors,\n",
    "The space in between = margin.\n",
    "\n",
    "ğŸ”„ What if toys and books are mixed and not separable by a straight rope?\n",
    "SVM then uses a \"magic trick\" called a kernel.\n",
    "\n",
    "Imagine lifting toys and books into the air and then slicing them with a flat sheet. Suddenly, they can be separated! âœ¨\n",
    "This trick is done using something called a Kernel Function, like:\n",
    "\n",
    "Linear Kernel (straight line)\n",
    "\n",
    "RBF Kernel (curved boundary â€” more flexible)\n",
    "\n",
    "ğŸ”§ SVM Important Settings (Hyperparameters)\n",
    "ğŸ”¸ C â€“ Regularization\n",
    "Controls how much SVM cares about correctly classifying each training example vs having a wider margin.\n",
    "\n",
    "Low C â†’ allow some mistakes but wider margin.\n",
    "\n",
    "High C â†’ tries to classify everything right, even if the margin is smaller.\n",
    "\n",
    "ğŸ”¸ gamma â€“ Only for RBF kernel\n",
    "Controls how far a single training example affects the boundary.\n",
    "\n",
    "Low gamma â†’ smoother boundary.\n",
    "\n",
    "High gamma â†’ more complex, wiggly boundary (can overfit).\n",
    "\n",
    "ğŸ›  What will we do in this task?\n",
    "Load Breast Cancer Dataset ğŸ§¬ (with sklearn.datasets)\n",
    "\n",
    "Preprocess the data (scale features using StandardScaler)\n",
    "\n",
    "Train two SVM models:\n",
    "\n",
    "Linear SVM\n",
    "\n",
    "Non-linear SVM (with RBF kernel)\n",
    "\n",
    "Visualize the decision boundary (for simple 2D data)\n",
    "\n",
    "Tune C and gamma to improve results\n",
    "\n",
    "Use cross-validation to test performance\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
